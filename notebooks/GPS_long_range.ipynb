{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import random\n",
    "\n",
    "# Add the absolute path to the src directory \n",
    "os.chdir('../src')\n",
    "src_path = os.path.abspath('../src/')\n",
    "sys.path.insert(0, src_path)\n",
    "\n",
    "from setup import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.multiprocessing as mp\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch_geometric.transforms import AddRandomWalkPE\n",
    "from torch_geometric.datasets import LRGBDataset\n",
    "\n",
    "\n",
    "# Enable multiprocessing for DataLoader and PyTorch\n",
    "torch.set_num_threads(mp.cpu_count() - 1)\n",
    "torch.set_num_interop_threads(mp.cpu_count() - 1)\n",
    "\n",
    "def load_cocosp(parallel=True, subset_ratio=1.0):\n",
    "    \"\"\"Preprocess and train-valid-test split COCO-SP data with optional subset size.\"\"\"\n",
    "    transform = AddRandomWalkPE(walk_length=20, attr_name='pe')\n",
    "    dataset = LRGBDataset(root='/tmp/COCO-SP', name='COCO-SP')\n",
    "    dataset = [transform(data) for data in dataset]\n",
    "\n",
    "    # Normalize labels\n",
    "    for data in dataset:\n",
    "        if data.y.ndim > 0:  # If data.y is not a scalar, take the first element\n",
    "            data.y = data.y[0]\n",
    "\n",
    "    min_label = min(data.y.item() for data in dataset)\n",
    "    for data in dataset:\n",
    "        data.y -= min_label\n",
    "\n",
    "    # Train-test split\n",
    "    train_split = int(len(dataset) * 0.8)\n",
    "    train_dataset = dataset[:train_split]\n",
    "    test_dataset = dataset[train_split:]\n",
    "\n",
    "    # Reduce dataset size for faster tests\n",
    "    if subset_ratio < 1.0:\n",
    "        import random\n",
    "        random.seed(42)\n",
    "        train_dataset = random.sample(train_dataset, max(1, int(len(train_dataset) * subset_ratio)))\n",
    "        test_dataset = random.sample(test_dataset, max(1, int(len(test_dataset) * subset_ratio)))\n",
    "\n",
    "    # DataLoader\n",
    "    num_workers = max(1, mp.cpu_count() - 2) if parallel else 0\n",
    "    train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True, num_workers=num_workers, pin_memory=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False, num_workers=num_workers, pin_memory=True)\n",
    "\n",
    "    num_classes = max(data.y.item() for data in dataset) + 1\n",
    "    return train_loader, test_loader, num_classes\n",
    "\n",
    "\n",
    "\n",
    "class GPSNodeClassifier(torch.nn.Module):\n",
    "    \"\"\"Graph Convolutional Network.\"\"\"\n",
    "    def __init__(self, num_node_features, hidden_channels, num_classes, num_layers):\n",
    "        super(GPSNodeClassifier, self).__init__()\n",
    "        self.convs = nn.ModuleList()\n",
    "        self.convs.append(GCNConv(num_node_features, hidden_channels))\n",
    "        for _ in range(num_layers - 1):\n",
    "            self.convs.append(GCNConv(hidden_channels, hidden_channels))\n",
    "        self.lin = nn.Linear(hidden_channels, num_classes)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        for conv in self.convs:\n",
    "            x = conv(x, edge_index)\n",
    "            x = F.relu(x)\n",
    "        return self.lin(x)\n",
    "\n",
    "\n",
    "def train_gps_nodes(model, data_loader, optimizer, device):\n",
    "    \"\"\"Training loop for GPS nodes.\"\"\"\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for data in data_loader:\n",
    "        data = data.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        out = model(data.x, data.edge_index)\n",
    "        loss = F.cross_entropy(out[data.train_mask], data.y[data.train_mask])\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    return total_loss / len(data_loader)\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def test_gps_nodes(model, data_loader, device):\n",
    "    \"\"\"Test loop for GPS nodes.\"\"\"\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for data in data_loader:\n",
    "        data = data.to(device)\n",
    "        out = model(data.x, data.edge_index)\n",
    "        pred = out.argmax(dim=1)\n",
    "        correct += (pred[data.test_mask] == data.y[data.test_mask]).sum().item()\n",
    "        total += data.test_mask.sum().item()\n",
    "    return correct / total\n",
    "\n",
    "\n",
    "def main():\n",
    "    # Configure multi-threading and device\n",
    "    num_workers = max(1, mp.cpu_count() - 2)\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    # Load data\n",
    "    cocosp_train_loader, cocosp_test_loader, num_classes = load_cocosp(subset_ratio=0.1)\n",
    "    first_batch = next(iter(cocosp_train_loader))\n",
    "    num_node_features = first_batch.x.shape[1]\n",
    "    # Model setup\n",
    "    model = GPSNodeClassifier(\n",
    "        num_node_features=num_node_features,\n",
    "        hidden_channels=128,\n",
    "        num_classes=num_classes,\n",
    "        num_layers=5\n",
    "    ).to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=1e-4)\n",
    "    scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=5)\n",
    "\n",
    "    print('Beginning training...')\n",
    "    # Training loop\n",
    "    for epoch in range(30):\n",
    "        train_loss = train_gps_nodes(model, cocosp_train_loader, optimizer, device)\n",
    "        test_acc = test_gps_nodes(model, cocosp_test_loader, device)\n",
    "        scheduler.step(train_loss)\n",
    "        print(f\"Epoch {epoch}: Train Loss={train_loss:.4f}, Test Acc={test_acc:.4f}\")\n",
    "\n",
    "\n",
    "'''if __name__ == \"__main__\":\n",
    "    main()\n",
    "'''\n",
    "\n",
    "main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dsc180",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
